# 6. 메모리와 캐시 메모리

## RAM의 특징과 종류
앞서 메모리란 주로 RAM을 지칭한다고 했었다. RAM은 CPU가 접근할 수 있으며 전원이 꺼지면 데이터가 날아가는 휘발성 저장 장치이다. 반면 보조 기억 장치는 전원이 꺼져도 데이터가 날아가지 않는 비휘발성 저장 장치이다.

이러한 특징 때문에 일반적으로 보조 기억 장치에는 데이터를 "보관"하고 RAM에는 실행 중인 프로그램 및 데이터를 "실행"하는 데 필요한 정보를 저장한다.

CPU는 보조기억장치에 직접 접근하지 못하기 때문에 실행할 대상이 보조기억장치에 있다면 이를 RAM으로 복사하여 저장한 뒤 실행한다. RAM 용량이 커지면 실행할 프로그램을 더 많이 저장할 수 있기 때문에 보조기억장치에서 프로그램을 복사, 저장하는 과정이 적게 들어서 성능적으로 여러 프로그램을 동시에 빠르게 실행하는 데 유리하다. 하지만 무조건 RAM 용량이 크다고 해서 성능이 비례하게 좋아지는 것은 아니며 필요 이상 RAM의 용량이 커져도 RAM이 데이터를 가져오는 속도가 CPU를 따라잡지 못한다면 CPU가 필요한 데이터를 기다리느라 시간을 낭비하게 되기 때문이다.

### DRAM (Dynamic RAM)
저장된 데이터가 동적으로 점점 사라지는 RAM을 말한다. 전원이 켜져 있어도 데이터가 소멸하기 때문에 주기적으로 재활성화 해줘야 한다. 상대적으로 소비전력이 낮고 저렴하다. 간단한 내부구조와 패턴을 가지고 있기 때문에 이를 겹쳐 대용량의 메모리로 만들 수 있으며, 이러한 이유로 DRAM은 일반적으로 메모리로 사용되는 RAM이다.

### SRAM (Static RAM)
전원이 연결되어 있다면 데이터가 소멸하지 않는 정적인 RAM이다. DRAM보다 소비전력이 많고 빠르다. 그리고 가격도 비싸다. 대용량의 메모리로 만들기 힘들기 때문에 대용량으로 설계할 필요는 없지만 빨라야 하는 저장 장치에 사용된다. 대표적으로 캐시 메모리에서 사용된다.

### SDRAM (Synchronous Dynamic RAM)
클럭 신호가 동기화된 발전된 형태의 DRAM이다. 클럭 신호가 동기화되었다는 것은 한 클럭에 CPU와 데이터를 주고받을 수 있다는 것을 의미한다.

### DDR SDRAM (Double Data Rate SDRAM)
DDR SDRAM은 SDRAM의 대역폭을 두 배로 늘린 형태이다. 여기서 대역폭이란 데이터를 주고받는 길의 너비를 나타낸다. SDRAM은 한 클럭당 한 번씩 CPU와 데이터를 주고받을 수 있는데, 반면 DDR SDRAM은 한 클럭당 두 번씩 주고받을 수 있어서 SDRAM보다 더 빠른 전송 속도를 가진다. 이와 대조적으로 한 클럭당 한 번씩 데이터를 주고받을 수 있는 SDRAM을 SDR SDRAM(Single Data Rate SDRAM)이라 부른다.

DDR2 SDRAM은 DDR SDRAM보다 대역폭이 두 배 넓은 SDRAM으로, DDR3 SDRAM은 DDR2 SDRAM보다 대역폭이 두 배 넓은 SDRAM이다. 최근에는 DDR4 SDRAM이 흔히 사용되며, 이는 SDR SDRAM보다 16배 넓은 대역폭을 가지고 있다.

### 메모리의 주소 공간
메모리의 주소 공간은 논리 주소와 물리 주소로 나뉜다. 논리 주소는 CPU와 실행 중인 프로그램이 사용하는 주소를 의미하며, 물리 주소는 실제 하드웨어 상의 주소를 나타낸다. 메모리에 저장되는 데이터는 시시각각 변하고 CPU와 실행 중인 프로그램이 이 주소를 계속 기억하고 있기란 어려운 일이므로, 추상적으로 논리 주소를 사용하는 것이다. 하지만 실제로 CPU가 메모리와 상호작용하려면 논리 주소를 물리 주소로 변환하는 과정이 필요하다. 이 변환 작업을 수행하는 것이 메모리 관리 장치(MMU)라는 하드웨어다.

논리 주소는 베이스 레지스터로부터 떨어진 거리를 표현하는데, MMU는 논리 주소와 베이스 레지스터의 값을 더하여 물리 주소로 변환한다. 이때, 베이스 레지스터는 프로그램이 저장되는 시작 주소를 말한다.

![스크린샷 2023-08-30 오후 10.30.06](https://i.imgur.com/f987KyQ.png)

### 메모리 보호 기법
논리 주소가 유효한 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 미치지 않도록 하는 기법이 필요하다. 이를 위해 한계 레지스터가 사용된다. 한계 레지스터는 유효한 논리 주소의 크기를 제한한다. 따라서 물리 주소는 베이스 레지스터값 이상부터 베이스 레지스터값 + 한계 레지스터값 미만의 범위를 가질 수 있게 된다.

![스크린샷 2023-08-31 오전 2.29.09](https://i.imgur.com/Jv9SEWU.png)

만약 CPU가 이 범위를 벗어나는 논리 주소에 접근하려고 하면 인터럽트가 발생하여 실행을 중단한다. 따라서 CPU가 메모리에 접근하는 과정은 다음과 같다.

![스크린샷 2023-08-31 오전 2.34.02](https://i.imgur.com/a205UsH.png)

## 저장 장치 계층 구조
저장 장치들의 특징 중 첫 번째로, CPU와 가까울수록 빠르고, 멀리 있을수록 느리다. 두 번째로, 속도가 빠른 저장 장치는 용량이 적고 가격이 비싸다는 특징이 있다. 이러한 특성을 토대로 저장 장치를 계층적으로 표현할 수 있는데, 이를 저장 장치 계층 구조라고 한다. 아래의 이미지와 같다.

![스크린샷 2023-08-31 오후 1.15.15](https://i.imgur.com/80Ki6Ja.png)

아래에 위치할수록 용량이 크고 속도가 느리며 가격이 저렴하고 위에 위치할수록 그 반대이다.

## 캐시 메모리
CPU가 메모리에 접근하는 속도는 CPU의 연산 속도보다 느리다. 연산이 빨리 끝나더라도 필요한 데이터가 늦게 도착하면 병목 현상이 발생한다. 이러한 병목 현상을 완화하기 위한 저장 장치가 **캐시 메모리**다. CPU와 메모리 사이에 위치하며 SRAM 기반의 저장 장치다.

캐시 메모리는 컴퓨터 내부에서 계층으로 구성되는데 L1, L2, L3 세 가지 레벨로 계층 구조를 이룬다. L1, L2, L3 순서로 점점 용량이 커지며 가격이 저렴해지고 속도가 느려진다. 일반적으로 L1, L2는 CPU 내부에 위치하며 L3는 CPU 외부에 존재한다.

CPU에 데이터가 필요하면 L1, L2, L3 순서로 데이터를 찾는다. 멀티 코어 프로세서에서는 코어마다 고유한 L1, L2 캐시를 가지며 L3는 여러 코어가 공유하게 된다.

## 참조 지역성 원리
캐시 메모리는 CPU가 자주 사용할 가능성이 높은 데이터를 예측하여 저장한다. 이 예측이 맞았을 경우, 즉 캐시 메모리에 CPU가 필요한 데이터가 있을 경우, 이를 "캐시 히트"라고 한다. 반대로 CPU가 필요한 데이터가 캐시 메모리에 없을 경우에는 "캐시 미스"라고 한다. 캐시가 히트되는 비율을 캐시 적중률이라 하며 다음과 같이 계산한다.
> 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

CPU가 사용할 가능성이 높은 데이터를 예측하는 방법으로 **참조 지역성 원리**가 사용된다. 참조 지역성 원리는 두 가지 원칙을 포함하고 있다. 첫 번째로, CPU는 최근에 접근한 데이터에 다시 접근하려는 경향이 있다. 이를 "시간 지역성"이라 하며, 빈번하게 사용되는 데이터를 변수로 저장하고 이 변수를 다시 참조하는 경우에 해당한다. 두 번째로, CPU는 접근한 메모리 공간 근처에 접근하려는 경향이 있다. 이를 "공간 지역성"이라 하며, 프로그램이 사용하는 데이터가 메모리 공간에 연속적으로 저장되는 경우에 해당한다.